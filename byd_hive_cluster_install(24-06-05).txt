

#########################################
##环境检查
#########################################

#检查subnet的连通性
#检查vm service account的权限 

roles/cloudkms.cryptoKeyDecrypter
roles/cloudkms.cryptoKeyEncrypter
Secret Manager Admin
Storage Admin



#########################################
##环境变量 env
#########################################
export REGION="southamerica-east1"
export ZONE="southamerica-east1-b"
export SUBNET="projects/baidao-bigdata-for-byd/regions/southamerica-east1/subnetworks/default"
export PROJECT="baidao-bigdata-for-byd"
export WAREHOUSE_BUCKET="br-ghy-bigdata-hive-prod-bd-2"

##新增openldap和ranger plugin所需的环境变量
export OPENLDAP_HOST="10.128.0.2"
export SSSD_BIND_PASS="123456"
export CLUSTER_ID="br-ghy-bigdata-hive-prod-new-1"
export RANGER_HOST="10.158.0.37"
export SLOR_HOST="10.158.0.37"

export MYSQL_INSTANCE="baidao-hive-metastore"
export ROOT_PASS="Baidao123.."




#########################################
##  1、创建数据库
#########################################

gcloud sql instances create ${MYSQL_INSTANCE} --database-version=MYSQL_8_0_33 --availability-type=regional --enable-bin-log \
    --no-assign-ip --root-password=${ROOT_PASS} --cpu=4 --memory=16GB --region=${REGION} --edition=enterprise \
    --database-flags lower_case_table_names=1,log_bin_trust_function_creators=on,log_output=FILE,slow_query_log=on,long_query_time=1 \
    --storage-size 500GB --storage-type=SSD --insights-config-query-insights-enabled \
    --network=projects/baidao-bigdata-for-byd/global/networks/default \
    --deletion-protect 




#########################################
##  2、创建dataproc桶
#########################################

gsutil mb -l ${REGION} -b on gs://${WAREHOUSE_BUCKET}

#copy初始化文件
将sh文件放到install文件夹中




#########################################
##  3、准备hive,oozie数据库的密码
#########################################

#hive 生成加密key

gcloud kms keyrings create bigdata-hive --location ${REGION}
gcloud kms keys create hive-metastore \
    --location ${REGION} \
    --keyring bigdata-hive \
    --purpose encryption


echo "byd770405" | \
gcloud kms encrypt \
    --location=${REGION} \
    --keyring=bigdata-hive \
    --key=hive-metastore \
    --plaintext-file=- \
    --ciphertext-file=admin-password.encrypted

gcloud storage cp ./admin-password.encrypted  gs://${WAREHOUSE_BUCKET}/hive-metastore-pwd/admin-password.encrypted

#oozie 生成加密secret

echo -n "byd770405" | gcloud secrets create mysql-root-password-secret-name \
    --replication-policy="automatic" \
    --data-file=-

echo -n "byd770405" | gcloud secrets create oozie-password-secret-name \
    --replication-policy="automatic" \
    --data-file=-


#########################################
##  4、ranger+openldap节点安装
#########################################
此处暂忽略


#########################################
##  5、创建Hive集群，并且初始化安装sssd服务
#########################################

gcloud dataproc clusters create ${CLUSTER_ID} \
    #--master-min-cpu-platform="Intel Ice Lake" --worker-min-cpu-platform="Intel Ice Lake" \ 机器资源不足
    --enable-component-gateway \
    --scopes cloud-platform \
    --tags br-ghy-bigdata \
    --no-address \
    --region ${REGION} \
    --zone ${ZONE} \
    --subnet ${SUBNET} \
    --num-masters=1 \
    --master-machine-type n2-standard-16 \
    --master-boot-disk-type pd-balanced \
    --master-boot-disk-size 500 \
    --num-workers 4 \
    --worker-machine-type n2-highmem-16 \
    --worker-boot-disk-type pd-balanced \
    --worker-boot-disk-size 500 \
    --optional-components ZOOKEEPER,trino,flink \
    --image-version 2.1-debian11 \
    --project ${PROJECT} \
    --bucket ${WAREHOUSE_BUCKET} \
    --initialization-actions gs://${WAREHOUSE_BUCKET}/install/cloud-sql-proxy.sh,gs://${WAREHOUSE_BUCKET}/install/sqoop.sh,gs://${WAREHOUSE_BUCKET}/install/byd_gcp_kyuubi.sh,gs://${WAREHOUSE_BUCKET}/install/oozie_byd.sh,gs://${WAREHOUSE_BUCKET}/install/byd_gcp_sssd.sh,gs://${WAREHOUSE_BUCKET}/install/byd_gcp_trino_ssl.sh,gs://${WAREHOUSE_BUCKET}/install/other_steps.sh \
    --properties "hive:hive.metastore.warehouse.dir=gs://${WAREHOUSE_BUCKET}/datasets" \
    --metadata "hive-metastore-instance=${PROJECT}:${REGION}:${MYSQL_INSTANCE}" \
    --metadata "use-cloud-sql-private-ip=true" \
    --metadata "kms-key-uri=projects/${PROJECT}/locations/${REGION}/keyRings/bigdata-hive/cryptoKeys/hive-metastore" \
    --metadata "db-admin-password-uri=gs://${WAREHOUSE_BUCKET}/hive-metastore-pwd/admin-password.encrypted" \
    --metadata "db-hive-password-uri=gs://${WAREHOUSE_BUCKET}/hive-metastore-pwd/admin-password.encrypted" \
    --metadata "oozie-password-secret-name=oozie-password-secret-name" \
    --metadata "mysql-root-password-secret-name=mysql-root-password-secret-name" \
    --metadata "openldap-host=${OPENLDAP_HOST}" \
    --metadata "sssd-bind-password=${SSSD_BIND_PASS}" \
    --metadata "cluster-id=${CLUSTER_ID}" \
    --metadata "solr-host=${SOLR_HOST}" \
    --metadata "ranger-host=${RANGER_HOST}" \
    --metadata "data-bucket=${WAREHOUSE_BUCKET}" \
    --metadata "block-project-ssh-keys=false" \
    --properties "core:hadoop.proxyuser.root.hosts=*" \
    --properties "core:hadoop.proxyuser.root.groups=*" \
    --properties "core:hadoop.proxyuser.hue.hosts=*" \
    --properties "core:hadoop.proxyuser.hue.groups=*" \
    --properties "core:hadoop.proxyuser.hadoop.hosts=*" \
    --properties "core:hadoop.proxyuser.hadoop.groups=*" \
    --properties "hdfs:dfs.webhdfs.enable=true" \
    --properties "yarn:yarn.scheduler.capacity.queue-mappings=u:hadoop:default" \
    --properties "yarn:yarn.scheduler.capacity.queue-mappings-override.enable=true" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.capacity=100" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.default.capacity=50" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.default.maximum-capacity=65" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.launcher-job.maximum-capacity=25" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.launcher-job.capacity=18" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.product.maximum-capacity=40" \
    --properties "capacity-scheduler:yarn.scheduler.capacity.root.product.capacity=32" \
    --properties ^#^capacity-scheduler:yarn.scheduler.capacity.root.queues=default,product,launcher-job \
    --properties "capacity-scheduler:yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.util.resource.DominantResourceCalculator" \
    --properties ^#^hive:tez.mrreader.config.update.properties=hive.io.file.readcolumn.names,hive.io.file.readcolumn.ids \
    --properties "hive:hive.vectorized.execution.enabled=false" \
    --properties "hive:iceberg.engine.hive.enabled=true" \
    --properties "hive:hive.server2.thrift.port=10000" \
    --properties "spark:spark.sql.legacy.parquet.nanosAsLong=false" \
    --properties "spark:spark.sql.parquet.enableVectorizedReader=false" \
    --properties "spark:spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog" \
    --properties "spark:spark.driver.extraClassPath=/usr/lib/iceberg/lib/iceberg-spark-runtime-3.3_2.12-1.4.3.jar" \
    --properties "spark:spark.executor.extraClassPath=/usr/lib/iceberg/lib/iceberg-spark-runtime-3.3_2.12-1.4.3.jar" \
    --properties ^#^spark:spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
    --properties "spark:spark.sql.catalog.spark_catalog.type=hive" \
    --properties "spark:spark.sql.codegen.maxFields=4000"


